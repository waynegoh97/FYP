import math

import numpy as np
import pandas as pd


def dirichlet_generate(csv_dir, save_dir):
    # store dictionary contains coordinates (latitude, longitude) as keys and rssi data as values (according to the number of samples belonging to coordinate) e.g. {(-7345.345, 4328596): [[AP0 ... AP520],[AP0 ... AP520]]}
    store = {}

    train_df = pd.read_csv(csv_dir, header=0)
    train_input = np.array(train_df.iloc[: ,:520])
    train_label = np.array(train_df.iloc[: ,520:522])
    for j in range(len(train_input)):
        k = train_label[j].tolist()
        v = train_input[j].tolist()

        if tuple(k) in store:
            store[tuple(k)].append(v)
        else:
            store[tuple(k)] = [v]

    ### Total dirichlet needed = 75 - original images, another 75 images is generated by GAN+, with a total of 150 images for localisation ###
    tempim = [] # contains [[[AP0...AP520] for N samples], [[AP0...AP520] for N samples]]]
    templb = [] # contains [[longitude,latitude],[longitude,latitude]]
    dirich_needed = []
    drop_key =[]
    count = 0
    ### np.random.dirichlet takes N samples weights, where N is the total number of samples in RP.
    ## N Dirichlet distribution adds up to 1.

    for k in store.keys():  # number of unique RP

        sample_size = len(store[k])
        dirich_needed.append(75 - sample_size)

        # randomly pick samples for dirichlet
        im_new = [[0 for i in range(sample_size)] for j in range(520)]
        curr_rp_samples = np.array(store[k])
        curr_rp_samples[curr_rp_samples == 100] = -110
        curr_rp_samples = curr_rp_samples.T
        # generate images according to dirichlet needed (contains excess)
        for gen in range(math.ceil(100 / sample_size)):
            for s in range(sample_size):
                weight = np.random.dirichlet(np.ones(sample_size), size=1)
                for ap in range(520):
                    im_new[ap][s] = np.sum(np.multiply(weight, curr_rp_samples[ap][:]))
                    if (110 + im_new[ap][s] <= 0.000001):
                        im_new[ap][s] = -110.0

            tempim.append((np.array(im_new).T).tolist())
            templb.append([k[0], k[1]])
        count += 1

    # Create column names
    col = ["AP" + str(i) for i in range(1, 521)]
    df = pd.DataFrame(tempim[0], columns=col)
    df["LATITUDE"] = templb[0][1]
    df["LONGITUDE"] = templb[0][0]
    for i in range(1, len(tempim)):
        df2 = pd.DataFrame(tempim[i], columns=col)
        df2["LATITUDE"] = templb[i][1]
        df2["LONGITUDE"] = templb[i][0]
        df = df.append(df2, ignore_index=True)

    # remove excess dirichlet generated
    col.append("LATITUDE")
    col.append("LONGITUDE")
    new_df = pd.DataFrame(columns=col)

    for key in store.keys():
        tdf = df[(df["LATITUDE"] == key[1]) & (df["LONGITUDE"] == key[0])]
        tdf = tdf.drop(tdf.index[range(len(tdf) - 100)])
        new_df = new_df.append(tdf, ignore_index=True)

    new_df.to_csv(save_dir, index=False)

if __name__ == "__main__":
    fid = "b0f0"
    csv_dir = "C:/Users/noxtu/LnF_FYP2122S1_Goh-Yun-Bo-Wayne/FYP_data/personal/csv_files/"+fid + "_train.csv"
    save_dir = "C:/Users/noxtu/LnF_FYP2122S1_Goh-Yun-Bo-Wayne/FYP_data/personal/csv_files/dirichlet/"+fid+ ".csv"
    dirichlet_generate(csv_dir, save_dir)